{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">DLOps - Deployment</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist.: PhD.Eddy Giusepe Chirinos Isidro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste script vamos aprender a desplegar (Deployment) nossos modelos em produção. Para isso usaremos [FastAPI](https://fastapi.tiangolo.com/), um *framework* de Python para o desenvolvimento de APIs, [Docker](https://www.docker.com/) para empacotar a API e  [Heroku](https://www.heroku.com/) para desplegar a PAI em produção. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que existe diferentes frameworks para criar APIs em Python, como `Flask` por exemplo, aqui vamos a usar `FastAPI`, já que oferece muitas funcionalidades que usaremos ao longo desta série de posts. Se não conheces este projeto, te recomendo que navegar por sua [Documentação](https://fastapi.tiangolo.com/tutorial/).\n",
    "\n",
    "\n",
    "> Podes instalar FastAPI com o comando `pip install fastapi[all]`.\n",
    "\n",
    "Uma vez instalado, cria um script chamado `app.py` com o seguinte conteúdo:\n",
    "\n",
    "\n",
    "```\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Hello World\"}\n",
    "```\n",
    "\n",
    "Agora, podemos começar tua API em local com o comando `uvicorn app:app --reload`. Se todo va bem, deverias ver um mensaje similar a:\n",
    "\n",
    "![](sen_3.png)\n",
    "\n",
    "Se agora abres teu navegador e digitas `http://localhost:8000/`, deverás ver a mensagem retornada pela API.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"message\": \"Hello World\"\n",
    "}\n",
    "```\n",
    "\n",
    "Sencillo, ¿verdad? Ahora simplemente tenemos que hacer que esta API (que como puedes ver no es más que un script de Python) carge nuestro modelo, reciba entradas (en nuestro caso imágenes) y devuelva las predicciones. Esto lo conseguiremos con el siguiente código:\n",
    "\n",
    "\n",
    "```\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from PIL import Image\n",
    "import onnxruntime as ort \n",
    "import numpy as np\n",
    "import io\n",
    "import math\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "ort_session = ort.InferenceSession('models/binary_classifier_3.onnx')\n",
    "TRHESHOLD = 0.5\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Hello World\"}\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    request_object_content = await file.read()\n",
    "    img = Image.open(io.BytesIO(request_object_content))\n",
    "    input = np.expand_dims(np.array(img, dtype=np.uint8), axis=0)\n",
    "    ort_inputs = {\n",
    "        \"input\": input\n",
    "    }\n",
    "    ort_output = ort_session.run(['output'], ort_inputs)[0]\n",
    "    output = sigmoid(ort_output)\n",
    "    return {\n",
    "        \"proba\": output,\n",
    "        \"label\": \"3\" if output > TRHESHOLD else \"no 3\"\n",
    "    }\n",
    "```\n",
    "\n",
    "Una de las ventajas que FastAPI ofrece es la de generación automática de documentación interactiva. Si visitas `http://localhost:8000/docs`, podrás probar tu nuevo *endpoint* al cual enviarle imágenes y recibir las predicciones del modelo. Siéntete libre de personalizar tu API a tu gusto 😁."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
